{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Authors.\n",
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/text_generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "tf.autograph.set_verbosity(3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='1400-0.txt'\n",
    "url='https://www.gutenberg.org/files/1400/1400-0.txt' # Great Expectations by Charles Dickens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = tf.keras.utils.get_file(file,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1014396 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path).read()\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Great Expectations\n",
      "\n",
      "[1867 Edition]\n",
      "\n",
      "by Charles Dickens\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      " Chapter I.\n",
      " Chapter II.\n",
      " Chapter III.\n",
      " Chapter IV.\n",
      " Chapter V.\n",
      " Chapter VI.\n",
      " Chapter VII.\n",
      " Chapter VIII.\n",
      " Chapter IX.\n",
      " Chapter X.\n",
      " Chapter XI.\n",
      " Chapter XII.\n",
      " Chapter XIII.\n",
      " Chapter XIV.\n",
      " Chapter XV.\n",
      " Chapter XVI.\n",
      " Chapter XVII.\n"
     ]
    }
   ],
   "source": [
    "# strip off text we don't need\n",
    "text = text[835:]\n",
    "\n",
    "# Take a look at the first 300 characters in text\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 unique characters.\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocabulary = sorted(set(text))\n",
    "print ('{} unique characters.'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '?': 28, '@': 29, 'A': 30, 'B': 31, 'C': 32, 'D': 33, 'E': 34, 'F': 35, 'G': 36, 'H': 37, 'I': 38, 'J': 39, 'K': 40, 'L': 41, 'M': 42, 'N': 43, 'O': 44, 'P': 45, 'Q': 46, 'R': 47, 'S': 48, 'T': 49, 'U': 50, 'V': 51, 'W': 52, 'X': 53, 'Y': 54, 'Z': 55, '[': 56, ']': 57, '_': 58, 'a': 59, 'b': 60, 'c': 61, 'd': 62, 'e': 63, 'f': 64, 'g': 65, 'h': 66, 'i': 67, 'j': 68, 'k': 69, 'l': 70, 'm': 71, 'n': 72, 'o': 73, 'p': 74, 'q': 75, 'r': 76, 's': 77, 't': 78, 'u': 79, 'v': 80, 'w': 81, 'x': 82, 'y': 83, 'z': 84, 'ê': 85, 'ô': 86, '—': 87, '‘': 88, '’': 89, '“': 90, '”': 91}\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary of unique characters to indices\n",
    "char_to_index = {char:index for index, char in enumerate(vocabulary)}\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t' '\\n' ' ' '!' '\"' '$' '%' '&' \"'\" '(' ')' '*' ',' '-' '.' '/' '0' '1'\n",
      " '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '?' '@' 'A' 'B' 'C' 'D' 'E' 'F'\n",
      " 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X'\n",
      " 'Y' 'Z' '[' ']' '_' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' 'ê' 'ô' '—' '‘' '’'\n",
      " '“' '”']\n"
     ]
    }
   ],
   "source": [
    "index_to_char = np.array(vocabulary)\n",
    "print(index_to_char)\n",
    "text_as_int = np.array([char_to_index[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\t':   0,\n",
      "  '\\n':   1,\n",
      "  ' ' :   2,\n",
      "  '!' :   3,\n",
      "  '\"' :   4,\n",
      "  '$' :   5,\n",
      "  '%' :   6,\n",
      "  '&' :   7,\n",
      "  \"'\" :   8,\n",
      "  '(' :   9,\n",
      "  ')' :  10,\n",
      "  '*' :  11,\n",
      "  ',' :  12,\n",
      "  '-' :  13,\n",
      "  '.' :  14,\n",
      "  '/' :  15,\n",
      "  '0' :  16,\n",
      "  '1' :  17,\n",
      "  '2' :  18,\n",
      "  '3' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char_to_index, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char_to_index[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n\\n\\n\\n\\nGreat Expe' ---- characters mapped to int ---- > [ 1  1  1  1  1 36 76 63 59 78  2 34 82 74 63]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 15 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:15]), text_as_int[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "sequence_length = 100\n",
    "examples_per_epoch = len(text)//sequence_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for char in char_dataset.take(5):\n",
    "  print(index_to_char[char.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n\\n\\n\\n\\nGreat Expectations\\n\\n[1867 Edition]\\n\\nby Charles Dickens\\n\\n\\nContents\\n\\n Chapter I.\\n Chapter II.\\n Cha'\n",
      "'pter III.\\n Chapter IV.\\n Chapter V.\\n Chapter VI.\\n Chapter VII.\\n Chapter VIII.\\n Chapter IX.\\n Chapter X.'\n",
      "'\\n Chapter XI.\\n Chapter XII.\\n Chapter XIII.\\n Chapter XIV.\\n Chapter XV.\\n Chapter XVI.\\n Chapter XVII.\\n C'\n",
      "'hapter XVIII.\\n Chapter XIX.\\n Chapter XX.\\n Chapter XXI.\\n Chapter XXII.\\n Chapter XXIII.\\n Chapter XXIV.\\n'\n",
      "' Chapter XXV.\\n Chapter XXVI.\\n Chapter XXVII.\\n Chapter XXVIII.\\n Chapter XXIX.\\n Chapter XXX.\\n Chapter X'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(index_to_char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted call: <function split_input_target at 0x7f34299bd040>\n",
      "    args: (<tf.Tensor 'args_0:0' shape=(101,) dtype=int64>,)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function split_input_target at 0x7f34299bd040>\n",
      "    args: (<tf.Tensor 'args_0:0' shape=(101,) dtype=int64>,)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Not allowed: <method-wrapper '__call__' of function object at 0x7f34299bd040>: default rule\n",
      "Not allowed: <method-wrapper '__call__' of function object at 0x7f34299bd040>: default rule\n",
      "INFO:tensorflow:Not allowed: <function split_input_target at 0x7f34299bd040>: default rule\n",
      "Not allowed: <function split_input_target at 0x7f34299bd040>: default rule\n",
      "INFO:tensorflow:<function split_input_target at 0x7f34299bd040> is not cached for subkey ConversionOptions[{}]\n",
      "<function split_input_target at 0x7f34299bd040> is not cached for subkey ConversionOptions[{}]\n",
      "INFO:tensorflow:Source code of <function split_input_target at 0x7f34299bd040>:\n",
      "\n",
      "def split_input_target(chunk):\n",
      "    input_text = chunk[:-1]\n",
      "    target_text = chunk[1:]\n",
      "    return input_text, target_text\n",
      "\n",
      "\n",
      "Source code of <function split_input_target at 0x7f34299bd040>:\n",
      "\n",
      "def split_input_target(chunk):\n",
      "    input_text = chunk[:-1]\n",
      "    target_text = chunk[1:]\n",
      "    return input_text, target_text\n",
      "\n",
      "\n",
      "INFO:tensorflow:Transformed <function split_input_target at 0x7f34299bd040>:\n",
      "\n",
      "# coding=utf-8\n",
      "def tf__split_input_target(chunk):\n",
      "    with ag__.FunctionScope('split_input_target', 'fscope', ag__.STD) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        input_text = ag__.ld(chunk)[:(- 1)]\n",
      "        target_text = ag__.ld(chunk)[1:]\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = (ag__.ld(input_text), ag__.ld(target_text))\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n",
      "Transformed <function split_input_target at 0x7f34299bd040>:\n",
      "\n",
      "# coding=utf-8\n",
      "def tf__split_input_target(chunk):\n",
      "    with ag__.FunctionScope('split_input_target', 'fscope', ag__.STD) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        input_text = ag__.ld(chunk)[:(- 1)]\n",
      "        target_text = ag__.ld(chunk)[1:]\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = (ag__.ld(input_text), ag__.ld(target_text))\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n",
      "INFO:tensorflow:Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__split_input_target at 0x7f342a094790> : None\n",
      "Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__split_input_target at 0x7f342a094790> : None\n",
      "INFO:tensorflow:KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__split_input_target at 0x7f342a094790> : None\n",
      "KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__split_input_target at 0x7f342a094790> : None\n",
      "INFO:tensorflow:Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__split_input_target at 0x7f342a094790> with\n",
      "    chunk: Tensor(\"args_0:0\", shape=(101,), dtype=int64)\n",
      "\n",
      "Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__split_input_target at 0x7f342a094790> with\n",
      "    chunk: Tensor(\"args_0:0\", shape=(101,), dtype=int64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '\\n\\n\\n\\n\\nGreat Expectations\\n\\n[1867 Edition]\\n\\nby Charles Dickens\\n\\n\\nContents\\n\\n Chapter I.\\n Chapter II.\\n Ch'\n",
      "Target data: '\\n\\n\\n\\nGreat Expectations\\n\\n[1867 Edition]\\n\\nby Charles Dickens\\n\\n\\nContents\\n\\n Chapter I.\\n Chapter II.\\n Cha'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(index_to_char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(index_to_char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 1 ('\\n')\n",
      "  expected output: 1 ('\\n')\n",
      "Step    1\n",
      "  input: 1 ('\\n')\n",
      "  expected output: 1 ('\\n')\n",
      "Step    2\n",
      "  input: 1 ('\\n')\n",
      "  expected output: 1 ('\\n')\n",
      "Step    3\n",
      "  input: 1 ('\\n')\n",
      "  expected output: 1 ('\\n')\n",
      "Step    4\n",
      "  input: 1 ('\\n')\n",
      "  expected output: 36 ('G')\n"
     ]
    }
   ],
   "source": [
    "for char, (input_index, target_index) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(char))\n",
    "    print(\"  input: {} ({:s})\".format(input_index, repr(index_to_char[input_index])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_index, repr(index_to_char[target_index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Batch size\n",
    "batch = 64\n",
    "steps_per_epoch = examples_per_epoch//batch\n",
    "\n",
    "# TF data maintains a buffer in memory in which to shuffle data\n",
    "# since it is designed to work with possibly endless data\n",
    "buffer = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer).batch(batch, drop_remainder=True)\n",
    "\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The vocabulary length in characterrs\n",
    "vocabulary_length = len(vocabulary)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dimension = 256\n",
    "\n",
    "# Number of RNN units\n",
    "recurrent_nn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-a4ddce29a501>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    recurrent_nn = tf.compat.v1.keras.layers.CuDNNGRU\n",
    "    print(\"GPU in use\")\n",
    "else:\n",
    "    import functools\n",
    "    recurrent_nn = functools.partial(tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
    "    print(\"CPU in use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(vocabulary_size, embedding_dimension, recurrent_nn_units, batch_size):\n",
    "    model = tf.keras.Sequential(\n",
    "        [tf.keras.layers.Embedding(vocabulary_size, embedding_dimension, batch_input_shape=[batch_size, None]),\n",
    "    recurrent_nn(recurrent_nn_units, return_sequences=True, recurrent_initializer='glorot_uniform', stateful=True),\n",
    "    tf.keras.layers.Dense(vocabulary_length)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocabulary_size = len(vocabulary),\n",
    "  embedding_dimension=embedding_dimension,\n",
    "  recurrent_nn_units=recurrent_nn_units,\n",
    "  batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 92) # (batch, sequence_length, vocabulary_length)\n"
     ]
    }
   ],
   "source": [
    "for batch_input_example, batch_target_example in dataset.take(1):\n",
    "    batch_predictions_example = model(batch_input_example)\n",
    "    print(batch_predictions_example.shape, \"# (batch, sequence_length, vocabulary_length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           23552     \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 92)            94300     \n",
      "=================================================================\n",
      "Total params: 4,056,156\n",
      "Trainable params: 4,056,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(logits=batch_predictions_example[0], num_samples=1)\n",
    "\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 84, 47, 14, 35, 37, 52, 88, 73, 53, 59, 56, 70, 74, 32, 19, 48,\n",
       "       11, 51, 58, 10, 43, 22, 73, 45, 84, 86, 72,  9, 79,  6, 20, 76,  7,\n",
       "       44, 63, 21, 49, 89, 11, 11, 66, 57, 75, 47, 65, 91, 39,  6, 24, 34,\n",
       "       90,  6, 18, 28, 84, 43, 68, 81, 89, 62, 67, 62, 36, 26, 73, 85, 28,\n",
       "       25, 69,  4, 86, 46, 62, 38,  8,  7, 41, 91, 54, 30, 49, 70, 79, 18,\n",
       "       83, 14,  9, 27,  2, 57, 78, 10, 16, 34, 20, 19, 30, 40, 45])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'sleeves, “I\\nhave probably done the most I can do; but if I can ever do more,—from a\\nWalworth point o'\n",
      "Next Char Predictions: \n",
      " '\"zR.FHW‘oXa[lpC3S*V_)N6oPzôn(u%4r&Oe5T’**h]qRg”J%8E“%2?zNjw’didG:oê?9k\"ôQdI\\'&L”YATlu2y.(; ]t)0E43AKP'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(index_to_char[batch_input_example[0]])))\n",
    "\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(index_to_char[sampled_indices ])))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 92)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.523453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_loss_example  = tf.compat.v1.losses.sparse_softmax_cross_entropy(batch_target_example, batch_predictions_example)\n",
    "print(\"Prediction shape: \", batch_predictions_example.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", batch_loss_example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next produced by upgrade script.... \n",
    "#model.compile(optimizer = tf.compat.v1.train.AdamOptimizer(), loss = loss) \n",
    "#.... but following optimizer is available.\n",
    "model.compile(optimizer = tf.optimizers.Adam(), loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "directory = './checkpoints'\n",
    "# Name of the checkpoint files\n",
    "file_prefix = os.path.join(directory, \"ckpt_{epoch}\")\n",
    "\n",
    "callback=[tf.keras.callbacks.ModelCheckpoint(filepath=file_prefix, save_weights_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>\n",
      "    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f342a17d910>,)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>\n",
      "    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f342a17d910>,)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:<function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0> is not cached for subkey ConversionOptions[{}]\n",
      "<function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0> is not cached for subkey ConversionOptions[{}]\n",
      "INFO:tensorflow:Source code of <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>:\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "def train_function(iterator):\n",
      "  \"\"\"Runs a training execution with one step.\"\"\"\n",
      "  return step_function(self, iterator)\n",
      "\n",
      "\n",
      "Source code of <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>:\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "def train_function(iterator):\n",
      "  \"\"\"Runs a training execution with one step.\"\"\"\n",
      "  return step_function(self, iterator)\n",
      "\n",
      "\n",
      "INFO:tensorflow:Transformed <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>:\n",
      "\n",
      "# coding=utf-8\n",
      "def tf__train_function(iterator):\n",
      "    'Runs a training execution with one step.'\n",
      "    with ag__.FunctionScope('train_function', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n",
      "Transformed <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>:\n",
      "\n",
      "# coding=utf-8\n",
      "def tf__train_function(iterator):\n",
      "    'Runs a training execution with one step.'\n",
      "    with ag__.FunctionScope('train_function', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n",
      "INFO:tensorflow:Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3428b835e0> : None\n",
      "Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3428b835e0> : None\n",
      "INFO:tensorflow:KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3428b835e0> : None\n",
      "KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3428b835e0> : None\n",
      "INFO:tensorflow:Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3428b835e0> with\n",
      "    iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f342a17d910>\n",
      "\n",
      "Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3428b835e0> with\n",
      "    iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f342a17d910>\n",
      "\n",
      "INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>\n",
      "    args: (<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3428cbfaf0>, <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f342a17d910>)\n",
      "    kwargs: None\n",
      "\n",
      "Converted call: <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>\n",
      "    args: (<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3428cbfaf0>, <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f342a17d910>)\n",
      "    kwargs: None\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3428b83e50>\n",
      "    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(64, 100) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3428b83e50>\n",
      "    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(64, 100) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3428b83e50>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3428b83e50>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function loss at 0x7f3428c21550>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function loss at 0x7f3428c21550>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Not allowed: <method-wrapper '__call__' of function object at 0x7f3428c21550>: default rule\n",
      "Not allowed: <method-wrapper '__call__' of function object at 0x7f3428c21550>: default rule\n",
      "INFO:tensorflow:Not allowed: <function loss at 0x7f3428c21550>: default rule\n",
      "Not allowed: <function loss at 0x7f3428c21550>: default rule\n",
      "INFO:tensorflow:<function loss at 0x7f3428c21550> is not cached for subkey ConversionOptions[{}]\n",
      "<function loss at 0x7f3428c21550> is not cached for subkey ConversionOptions[{}]\n",
      "INFO:tensorflow:Source code of <function loss at 0x7f3428c21550>:\n",
      "\n",
      "def loss(labels, logits):\n",
      "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
      "\n",
      "\n",
      "Source code of <function loss at 0x7f3428c21550>:\n",
      "\n",
      "def loss(labels, logits):\n",
      "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
      "\n",
      "\n",
      "INFO:tensorflow:Transformed <function loss at 0x7f3428c21550>:\n",
      "\n",
      "# coding=utf-8\n",
      "def tf__loss(labels, logits):\n",
      "    with ag__.FunctionScope('loss', 'fscope', ag__.STD) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.converted_call(ag__.ld(tf).keras.losses.sparse_categorical_crossentropy, (ag__.ld(labels), ag__.ld(logits)), dict(from_logits=True), fscope)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed <function loss at 0x7f3428c21550>:\n",
      "\n",
      "# coding=utf-8\n",
      "def tf__loss(labels, logits):\n",
      "    with ag__.FunctionScope('loss', 'fscope', ag__.STD) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.converted_call(ag__.ld(tf).keras.losses.sparse_categorical_crossentropy, (ag__.ld(labels), ag__.ld(logits)), dict(from_logits=True), fscope)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n",
      "INFO:tensorflow:Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420469ee0> : None\n",
      "Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420469ee0> : None\n",
      "INFO:tensorflow:KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420469ee0> : None\n",
      "KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420469ee0> : None\n",
      "INFO:tensorflow:Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420469ee0> with\n",
      "    labels: Tensor(\"IteratorGetNext:1\", shape=(64, 100), dtype=int64)\n",
      "    logits: Tensor(\"sequential/dense/BiasAdd:0\", shape=(64, 100, 92), dtype=float32)\n",
      "\n",
      "Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420469ee0> with\n",
      "    labels: Tensor(\"IteratorGetNext:1\", shape=(64, 100), dtype=int64)\n",
      "    logits: Tensor(\"sequential/dense/BiasAdd:0\", shape=(64, 100, 92), dtype=float32)\n",
      "\n",
      "INFO:tensorflow:Converted call: <function sparse_categorical_crossentropy at 0x7f3433208ee0>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {'from_logits': True}\n",
      "\n",
      "Converted call: <function sparse_categorical_crossentropy at 0x7f3433208ee0>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {'from_logits': True}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function sparse_categorical_crossentropy at 0x7f3433208ee0>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function sparse_categorical_crossentropy at 0x7f3433208ee0>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: (<tf.Tensor 'loss/weighted_loss/value:0' shape=() dtype=float32>,)\n",
      "    kwargs: {'sample_weight': <tf.Tensor 'strided_slice:0' shape=() dtype=int32>}\n",
      "\n",
      "Converted call: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: (<tf.Tensor 'loss/weighted_loss/value:0' shape=() dtype=float32>,)\n",
      "    kwargs: {'sample_weight': <tf.Tensor 'strided_slice:0' shape=() dtype=int32>}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function _all_reduce_sum_fn at 0x7f343325ee50>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, ((<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)))\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function _all_reduce_sum_fn at 0x7f343325ee50>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, ((<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)))\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function _all_reduce_sum_fn at 0x7f343325ee50>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function _all_reduce_sum_fn at 0x7f343325ee50>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}})\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'name': None}\n",
      "\n",
      "Converted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}})\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'name': None}\n",
      "\n",
      "INFO:tensorflow:Forwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}) with\n",
      "(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}) with\n",
      "(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n",
      "INFO:tensorflow:Converted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n",
      "Converted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>: DoNotConvert rule for tensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowlisted: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f34203f51c0>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>\n",
      "    args: (<tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420465670>: from cache\n",
      "INFO:tensorflow:Converted call: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: ()\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: ()\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>\n",
      "    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f34203d4cd0>,)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0>\n",
      "    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f34203d4cd0>,)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Cache hit for <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0> subkey ConversionOptions[{}]: <tensorflow.python.autograph.pyct.transpiler._PythonFnFactory object at 0x7f342c61b1c0>\n",
      "Cache hit for <function Model.make_train_function.<locals>.train_function at 0x7f3433de25e0> subkey ConversionOptions[{}]: <tensorflow.python.autograph.pyct.transpiler._PythonFnFactory object at 0x7f342c61b1c0>\n",
      "INFO:tensorflow:Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3420465310> : None\n",
      "Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3420465310> : None\n",
      "INFO:tensorflow:KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3420465310> : None\n",
      "KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3420465310> : None\n",
      "INFO:tensorflow:Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3420465310> with\n",
      "    iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f34203d4cd0>\n",
      "\n",
      "Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__train_function at 0x7f3420465310> with\n",
      "    iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f34203d4cd0>\n",
      "\n",
      "INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>\n",
      "    args: (<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3428cbfaf0>, <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f34203d4cd0>)\n",
      "    kwargs: None\n",
      "\n",
      "Converted call: <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>\n",
      "    args: (<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3428cbfaf0>, <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f34203d4cd0>)\n",
      "    kwargs: None\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>: from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowlisted <function Model.make_train_function.<locals>.step_function at 0x7f342a0945e0>: from cache\n",
      "INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3420465ca0>\n",
      "    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(64, 100) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3420465ca0>\n",
      "    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(64, 100) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3420465ca0>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7f3420465ca0>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>: from cache\n",
      "Allowlisted <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.LossFunctionWrapper object at 0x7f34299b2a60>>: from cache\n",
      "INFO:tensorflow:Converted call: <function loss at 0x7f3428c21550>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function loss at 0x7f3428c21550>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Not allowed: <method-wrapper '__call__' of function object at 0x7f3428c21550>: default rule\n",
      "Not allowed: <method-wrapper '__call__' of function object at 0x7f3428c21550>: default rule\n",
      "INFO:tensorflow:Not allowed: <function loss at 0x7f3428c21550>: default rule\n",
      "Not allowed: <function loss at 0x7f3428c21550>: default rule\n",
      "INFO:tensorflow:Cache hit for <function loss at 0x7f3428c21550> subkey ConversionOptions[{}]: <tensorflow.python.autograph.pyct.transpiler._PythonFnFactory object at 0x7f3428bee700>\n",
      "Cache hit for <function loss at 0x7f3428c21550> subkey ConversionOptions[{}]: <tensorflow.python.autograph.pyct.transpiler._PythonFnFactory object at 0x7f3428bee700>\n",
      "INFO:tensorflow:Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420376dc0> : None\n",
      "Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420376dc0> : None\n",
      "INFO:tensorflow:KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420376dc0> : None\n",
      "KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420376dc0> : None\n",
      "INFO:tensorflow:Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420376dc0> with\n",
      "    labels: Tensor(\"IteratorGetNext:1\", shape=(64, 100), dtype=int64)\n",
      "    logits: Tensor(\"sequential/dense/BiasAdd:0\", shape=(64, 100, 92), dtype=float32)\n",
      "\n",
      "Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__loss at 0x7f3420376dc0> with\n",
      "    labels: Tensor(\"IteratorGetNext:1\", shape=(64, 100), dtype=int64)\n",
      "    logits: Tensor(\"sequential/dense/BiasAdd:0\", shape=(64, 100, 92), dtype=float32)\n",
      "\n",
      "INFO:tensorflow:Converted call: <function sparse_categorical_crossentropy at 0x7f3433208ee0>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {'from_logits': True}\n",
      "\n",
      "Converted call: <function sparse_categorical_crossentropy at 0x7f3433208ee0>\n",
      "    args: (<tf.Tensor 'IteratorGetNext:1' shape=(64, 100) dtype=int64>, <tf.Tensor 'sequential/dense/BiasAdd:0' shape=(64, 100, 92) dtype=float32>)\n",
      "    kwargs: {'from_logits': True}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function sparse_categorical_crossentropy at 0x7f3433208ee0>: from cache\n",
      "Allowlisted <function sparse_categorical_crossentropy at 0x7f3433208ee0>: from cache\n",
      "INFO:tensorflow:Converted call: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: (<tf.Tensor 'loss/weighted_loss/value:0' shape=() dtype=float32>,)\n",
      "    kwargs: {'sample_weight': <tf.Tensor 'strided_slice:0' shape=() dtype=int32>}\n",
      "\n",
      "Converted call: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: (<tf.Tensor 'loss/weighted_loss/value:0' shape=() dtype=float32>,)\n",
      "    kwargs: {'sample_weight': <tf.Tensor 'strided_slice:0' shape=() dtype=int32>}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: from cache\n",
      "Allowlisted <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: from cache\n",
      "INFO:tensorflow:Converted call: <function _all_reduce_sum_fn at 0x7f343325ee50>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, ((<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)))\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function _all_reduce_sum_fn at 0x7f343325ee50>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, ((<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)))\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function _all_reduce_sum_fn at 0x7f343325ee50>: from cache\n",
      "Allowlisted <function _all_reduce_sum_fn at 0x7f343325ee50>: from cache\n",
      "INFO:tensorflow:Converted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}})\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'name': None}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}})\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'name': None}\n",
      "\n",
      "INFO:tensorflow:Forwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}) with\n",
      "(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n",
      "Forwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}) with\n",
      "(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n",
      "INFO:tensorflow:Converted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>\n",
      "    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x7f3428cbfca0>, [(<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>, <tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (<tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>, <tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>, <tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>)])\n",
      "    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}, ('/job:localhost/replica:0/task:0/device:CPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity_3:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul_1:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const_1:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_4:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow_2:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_6:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_5:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_3:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_7:0' shape=() dtype=float32>}}, 'name': None}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>: from cache\n",
      "Allowlisted <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f3428cf6bb0>>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'embedding/embeddings:0' shape=(92, 256) dtype=float32>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f342035b700>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: DoNotConvert rule for tensorflow\n",
      "Allowlisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: DoNotConvert rule for tensorflow\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'cu_dnngru/kernel:0' shape=(256, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN:0' shape=(256, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'cu_dnngru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_1:0' shape=(1024, 3072) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'cu_dnngru/bias:0' shape=(6144,) dtype=float32>, <tf.Tensor 'Adam/gradients/AddN_2:0' shape=(6144,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'dense/kernel:0' shape=(1024, 92) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/Tensordot/MatMul/MatMul_1:0' shape=(1024, 92) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "INFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>\n",
      "    args: (<tf.Variable 'dense/bias:0' shape=(92,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(92,) dtype=float32>)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "Allowlisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x7f3420469280>: from cache\n",
      "INFO:tensorflow:Converted call: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: ()\n",
      "    kwargs: {}\n",
      "\n",
      "Converted call: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>\n",
      "    args: ()\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Allowlisted <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: from cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowlisted <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f342a187850>>: from cache\n",
      "158/158 [==============================] - 4s 20ms/step - loss: 3.2360\n",
      "Epoch 2/45\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 2.0621\n",
      "Epoch 3/45\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.7342\n",
      "Epoch 4/45\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.5493\n",
      "Epoch 5/45\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.4344\n",
      "Epoch 6/45\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3569\n",
      "Epoch 7/45\n",
      "158/158 [==============================] - 3s 20ms/step - loss: 1.3015\n",
      "Epoch 8/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.2573\n",
      "Epoch 9/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.2184\n",
      "Epoch 10/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.1869\n",
      "Epoch 11/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.1509\n",
      "Epoch 12/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.1157\n",
      "Epoch 13/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.0835\n",
      "Epoch 14/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.0511\n",
      "Epoch 15/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 1.0211\n",
      "Epoch 16/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.9847\n",
      "Epoch 17/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.9529\n",
      "Epoch 18/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.9187\n",
      "Epoch 19/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.8822\n",
      "Epoch 20/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.8509\n",
      "Epoch 21/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.8204\n",
      "Epoch 22/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.7917\n",
      "Epoch 23/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.7674\n",
      "Epoch 24/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.7434\n",
      "Epoch 25/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.7203\n",
      "Epoch 26/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.7026\n",
      "Epoch 27/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6863\n",
      "Epoch 28/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6725\n",
      "Epoch 29/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6584\n",
      "Epoch 30/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6476\n",
      "Epoch 31/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6399\n",
      "Epoch 32/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6375\n",
      "Epoch 33/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6239\n",
      "Epoch 34/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6183\n",
      "Epoch 35/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6149\n",
      "Epoch 36/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6096\n",
      "Epoch 37/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6055\n",
      "Epoch 38/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.6030\n",
      "Epoch 39/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5976\n",
      "Epoch 40/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5991\n",
      "Epoch 41/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5944\n",
      "Epoch 42/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5966\n",
      "Epoch 43/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5922\n",
      "Epoch 44/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5930\n",
      "Epoch 45/45\n",
      "158/158 [==============================] - 3s 19ms/step - loss: 0.5967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/ckpt_45'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocabulary_size, embedding_dimension, recurrent_nn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(directory))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            21504     \n",
      "_________________________________________________________________\n",
      "unified_gru_1 (UnifiedGRU)   (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86100     \n",
      "=================================================================\n",
      "Total params: 4,045,908\n",
      "Trainable params: 4,045,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(model, start_string, temperature, characters_to_generate):\n",
    "\n",
    "  # Vectorise  start string into numbers\n",
    "    input_string = [char_to_index[char] for char in start_string]\n",
    "    input_string = tf.expand_dims(input_string, 0)\n",
    "\n",
    "  # Empty string to store  generated text\n",
    "    generated = []\n",
    "\n",
    "  # (Batch size is 1)\n",
    "    model.reset_states()\n",
    "    for i in range(characters_to_generate):\n",
    "        predictions = model(input_string)\n",
    "      # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(logits=predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "        input_string = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        generated.append(index_to_char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(generated)) # generated is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pip!”\n",
      "\n",
      "“So it was.”\n",
      "\n",
      "“Astonishing!” said Joe, in the nature of an umbrella.\n",
      "\n",
      "“Then, as it were now as for the other convict. “The fear of our own little nor\n",
      "stones of the forge. I was falling into my head to look if the way by which I had come to be a man. A deserting your mind to him, my indertrodic work in any convicts!” Then both very well. I\n",
      "thought it would have been more crack with the forge and Mill Pond Bank, Clara\n",
      "was not a variety of being in common black piece of paper, and put the two convicts were\n",
      "bought, the more certain I am of a circle.\n",
      "\n",
      "“Lookee here, Pip, look at his door.\n",
      "\n",
      "In the evening there was a lady by which I was always creeping the fire at the windows of the copyright holder), the waiter reappeared.\n",
      "\n",
      "“Why you see, old chap. They'll do you suppose the attempt to do it\n",
      "distinctly thanked him and said that Mr. Pumblechook was on my shoulder by some one\n",
      "of these days, and as Mr. Pumblechook was not at all likely he could\n",
      "have done it. I had done it, under the silence \n"
     ]
    }
   ],
   "source": [
    "# In the arguments, a low temperature gives more predictable text whereas a high temperature gives more random text.\n",
    "# Also this is where you can change the start string.\n",
    "generated_text = generate_text(model=model, start_string=\"Pip\", temperature=0.1, characters_to_generate = 1000)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
