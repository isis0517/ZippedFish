{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "#%config Completer.use_jedi = False\n",
    "#tf.autograph.set_verbosity(3, True)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12001,)\n",
      "512 unique characters.\n"
     ]
    }
   ],
   "source": [
    "text = np.load(\"fish_murme2.npy\")\n",
    "print(text.shape)\n",
    "# The unique characters in the file\n",
    "vocabulary = sorted(set(text))\n",
    "print ('{} unique characters.'.format(len(vocabulary)))\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "c2emb = {char:index for index, char in enumerate(vocabulary)}\n",
    "emb2c = np.array(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 500\n",
    "examples_per_epoch = len(text)//sequence_length\n",
    "text_emb = np.array([c2emb[code] for code in text])\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390 395 395 395 395 393 393 250 250 250 250 250 250 252 252 252 256 251\n",
      " 252 258 252 258 240 387 372 214  42  42 216 217  26  30  30 184 196 177\n",
      " 345 180 145 144 145 145 328 325 345 345 143 143 143 143   4 177 143 142\n",
      " 320 444 442 318 318 442 448 448 324 324 320 324 137 141 141 320 444 444\n",
      " 334 323 323 137 137 324 324 320 136 137 141 189 355 356 373  92  96  99\n",
      "  99 247 247 248 251 251 245 256 256 103 256 256 398 486 394 128 253 251\n",
      " 251 252 395 252 103 252 487 483 101 103  93  90  94  11  13 257 484 484\n",
      " 395 395 395 395 395 395 395 403 403 483 464 487 484 398 398 398 394 398\n",
      " 331 330 395 252 159 330 252 256 256 252 252 256 252 252 267 265 158 156\n",
      " 281 282 117 117 289 289 285 290 290 290 286 132 311 311 433 433 434 312\n",
      " 312 317 317 171 337 446 447 443 448 444 448 448 448 448 443 326 329 329\n",
      " 329 329 451 448 449 449 444 325 318 448 448 319 324 324 448 320 324 324\n",
      " 320 324 324 320 141 141 137 137 137 137 141 141 141 176 343 349 459 459\n",
      " 460 461 460 461 350 350 347 350 350 350 347 347 347 347 179 179 347 350\n",
      " 347 346 349 459 459 460 458 458 345 347 347 347 347 347 347 179 179 347\n",
      " 347 181 179 179 179 327 325 328 302 302 300 300 300 505 425 298 296 123\n",
      " 123 425 507 437 317 315 301 301 317 314 438 438 314 297 298 315 438 438\n",
      " 426 320 452 324 324 319 323 322 343 323 319 319 444 455 344 448 324 324\n",
      " 327 329 347 146 179 146 141 321 445 445 448 448 443 443 444 444 448 320\n",
      " 324 324 324 324 320 324 320 324 320 320 320 320 137 137 137 320 320 137\n",
      " 141 137 137 137 137   5   6 320 425 135 448 448 443 320 444 320 320 137\n",
      " 137 320 336 169 137 169 169 169 169 141 343 175 175 454 443 448 324 176\n",
      " 324 324 324 344 324 141 137 324 141 137 137 141 141 141 179 346 349 459\n",
      " 460 460 458 460 460 461 350 347 347 347 350 347 350 347 350 181 181 174\n",
      " 179 181 174 342 320 137 135 135 318 324 324 319 324 342 176 141 344 176\n",
      " 176 176 176 176 176 141 141 137   3  29 349 349 459 459 460 345 345 460\n",
      " 347 460 347 347 347 347 347 179 179 179 179 179 179 179 179 179 179 179\n",
      " 179 179  29 181  29 179 346 346 347 347 345 461 459 346 460]\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(sequence_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(1):\n",
    "      print(item.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "(<tf.Tensor: shape=(20, 500), dtype=int64, numpy=\n",
      "array([[480, 380, 229, ..., 172,  23,  22],\n",
      "       [230, 230, 230, ..., 391, 255, 255],\n",
      "       [366, 366, 366, ..., 385, 385, 230],\n",
      "       ...,\n",
      "       [194, 194, 194, ..., 366, 366, 366],\n",
      "       [367, 477, 477, ..., 380, 229, 229],\n",
      "       [395, 403, 403, ..., 143, 143, 345]])>, <tf.Tensor: shape=(20, 500), dtype=int64, numpy=\n",
      "array([[380, 229, 229, ...,  23,  22, 171],\n",
      "       [230, 230, 230, ..., 255, 255, 394],\n",
      "       [366, 366, 366, ..., 385, 230, 230],\n",
      "       ...,\n",
      "       [194, 194, 194, ..., 366, 366, 366],\n",
      "       [477, 477, 475, ..., 229, 229, 381],\n",
      "       [403, 403, 483, ..., 143, 345, 350]])>)\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "batch = 20\n",
    "print(examples_per_epoch)\n",
    "steps_per_epoch = examples_per_epoch//batch\n",
    "\n",
    "# TF data maintains a buffer in memory in which to shuffle data\n",
    "# since it is designed to work with possibly endless data\n",
    "buffer = 10000\n",
    "\n",
    "dataset = dataset.shuffle(10000).batch(batch_size=batch, drop_remainder=True)\n",
    "\n",
    "#dataset = dataset.repeat()\n",
    "for a in dataset.take(1):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The vocabulary length in characterrs\n",
    "vocabulary_length = len(vocabulary)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dimension = 512\n",
    "\n",
    "# Number of RNN units\n",
    "recurrent_nn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a4ddce29a501>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    recurrent_nn = tf.compat.v1.keras.layers.CuDNNGRU\n",
    "    print(\"GPU in use\")\n",
    "else:\n",
    "    import functools\n",
    "    recurrent_nn = functools.partial(tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
    "    print(\"CPU in use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocabulary_size, embedding_dimension, recurrent_nn_units, batch_size):\n",
    "    model = tf.keras.Sequential(\n",
    "        [tf.keras.layers.Embedding(vocabulary_size, embedding_dimension, batch_input_shape=[batch_size, None]),\n",
    "    recurrent_nn(recurrent_nn_units, return_sequences=True, recurrent_initializer='glorot_uniform', stateful=True),\n",
    "    tf.keras.layers.Dense(vocabulary_length)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocabulary_size = len(vocabulary),\n",
    "  embedding_dimension=embedding_dimension,\n",
    "  recurrent_nn_units=recurrent_nn_units,\n",
    "  batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((20, 500), (20, 500)), types: (tf.int64, tf.int64)>\n",
      "Input data:  tf.Tensor(\n",
      "[[198 204  52 ... 185 185  35]\n",
      " [ 32  24  39 ... 366 366 363]\n",
      " [381 381 381 ... 206 362 204]\n",
      " ...\n",
      " [366 366 366 ... 385 385 230]\n",
      " [210 207 204 ... 224 227 224]\n",
      " [480 380 229 ... 172  23  22]], shape=(20, 500), dtype=int64)\n",
      "Target data: tf.Tensor(\n",
      "[[204  52 215 ... 185  35  35]\n",
      " [ 24  39  32 ... 366 363 366]\n",
      " [381 381 381 ... 362 204 200]\n",
      " ...\n",
      " [366 366 366 ... 385 230 230]\n",
      " [207 204 204 ... 227 224 227]\n",
      " [380 229 229 ...  23  22 171]], shape=(20, 500), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.take(10))\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print ('Input data: ', input_example)\n",
    "    print ('Target data:', target_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((20, 500), (20, 500)), types: (tf.int64, tf.int64)>\n",
      "tf.Tensor(\n",
      "[[237  82 237 ... 201 201 201]\n",
      " [230  77 230 ... 230 230 230]\n",
      " [230 237 230 ... 381 381 381]\n",
      " ...\n",
      " [381 381 381 ... 206 362 204]\n",
      " [385 385 381 ... 233 380 478]\n",
      " [227 224  74 ... 230  77 228]], shape=(20, 500), dtype=int64)\n",
      "(20, 500, 512) # (batch, sequence_length, vocabulary_length)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.take(1))\n",
    "for batch_input_example, batch_target_example in dataset.take(1):\n",
    "    print(batch_input_example)\n",
    "    batch_predictions_example = model(batch_input_example)\n",
    "    print(batch_predictions_example.shape, \"# (batch, sequence_length, vocabulary_length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (20, None, 512)           262144    \n",
      "_________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)       (20, None, 1024)          4724736   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (20, None, 512)           524800    \n",
      "=================================================================\n",
      "Total params: 5,511,680\n",
      "Trainable params: 5,511,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(logits=batch_predictions_example[0], num_samples=1)\n",
    "\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([289, 309,  45, 358, 218, 180, 168, 350,  18, 411, 180, 427, 312,\n",
       "       404,  30, 223, 343, 130, 478, 371,  52, 317, 418, 453, 109, 510,\n",
       "       185, 343, 330, 114, 136,  69, 181, 488, 440, 331, 142, 498,  87,\n",
       "       336, 274, 429, 160, 353, 216, 177,  10, 415, 181, 264, 398,  65,\n",
       "       328, 145, 409,  20,  17, 161, 498,  35, 417,  38,  12,  53,  33,\n",
       "        68,  30, 340, 189,  62, 275, 477, 111,  99, 350, 455, 412,  44,\n",
       "       158, 308, 370, 444,  72, 187, 184, 334, 231, 506, 300,  49, 465,\n",
       "       317,   5, 409,  39, 451, 509, 510, 425, 278, 246,  43, 291, 263,\n",
       "       108, 335, 160, 510, 162, 181, 124, 410, 429, 463, 191, 344, 383,\n",
       "       390, 312, 316, 336, 252,  65,  12,  66, 360, 319, 484, 404, 497,\n",
       "        87, 444, 214, 438, 186, 261, 189, 285,  62, 479, 160, 248, 301,\n",
       "       265, 340, 198, 248, 217, 225, 450, 144, 447, 164, 494, 309, 366,\n",
       "        42, 388, 198, 289,  67,  83, 446, 230, 278,  55, 434, 168, 111,\n",
       "       101, 395,  73, 470, 184, 444,  39, 438,  77,  24, 310, 331, 444,\n",
       "       150, 466, 287, 405, 215, 473, 477, 295,  71, 117, 445,  33, 460,\n",
       "       397,  82, 124, 171, 128, 402,  72, 502, 220, 396,  19, 268,  19,\n",
       "        13, 362,  39, 500, 274, 322, 486,   0, 395,  34, 114, 178, 230,\n",
       "       106, 481, 219, 200, 203, 398, 465,  74, 126, 325, 234,  23, 267,\n",
       "       105, 210, 286, 148, 460, 140, 399, 449, 357, 327, 424, 336, 183,\n",
       "        98, 381, 480, 116, 192, 114, 477, 114, 235, 245, 478, 280, 398,\n",
       "       316, 330, 149, 310, 431, 353, 151, 300,  18, 102, 328, 315, 496,\n",
       "       308, 267, 326, 102, 282, 222,  79, 229, 498, 342, 325, 173, 302,\n",
       "       403, 383, 458, 135, 366, 132, 467, 306,   4,  44, 496, 510,  58,\n",
       "       310, 366, 247, 356, 427, 447, 159, 146,  34,  88, 381, 131, 168,\n",
       "       254, 492, 243,  38, 206, 182,  14, 493, 373,  60, 102, 439, 363,\n",
       "       394, 499,  47,  75, 147,  47,  79, 294, 315, 228, 326, 456, 382,\n",
       "       368, 110, 202, 303, 106, 106, 471, 134, 507, 125, 122, 384, 480,\n",
       "       191,  90, 132, 349, 430, 405,  99, 269, 252, 327, 394,  28,  81,\n",
       "       157, 434, 326,  31, 423,  65, 340, 462,  19, 221, 496, 268, 393,\n",
       "       452, 344, 287, 120,  75, 213,  71,  56, 129, 138, 451, 158, 152,\n",
       "       376, 354, 381, 130, 410, 464, 195, 176, 106, 457, 436, 383,  23,\n",
       "       281,  86, 287, 105, 417, 477, 388,   4, 179,   7, 507, 479, 348,\n",
       "       234, 408, 508, 303, 238, 314,  28, 232,  60, 196, 456, 446, 232,\n",
       "       468,  87, 153, 421, 286, 372, 203,  12, 352, 490, 130, 327,  74,\n",
       "        70, 289,  29, 409, 355, 153, 104, 348,  19, 191, 387, 271,  97,\n",
       "        62, 451,   5,  61, 264, 107, 227, 155, 165, 113, 340,  42,  77,\n",
       "       349, 278, 293, 162, 361, 498, 116, 208, 411,  71, 190, 312,  30,\n",
       "       135, 471, 105, 453, 298,  31, 158, 295, 146, 501, 305, 442, 466,\n",
       "       383, 246, 290, 407,  81,  51])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (20, 500, 512)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       6.2385006\n"
     ]
    }
   ],
   "source": [
    "batch_loss_example  = tf.compat.v1.losses.sparse_softmax_cross_entropy(batch_target_example, batch_predictions_example)\n",
    "print(\"Prediction shape: \", batch_predictions_example.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", batch_loss_example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next produced by upgrade script.... \n",
    "#model.compile(optimizer = tf.compat.v1.train.AdamOptimizer(), loss = loss) \n",
    "#.... but following optimizer is available.\n",
    "model.compile(optimizer = tf.optimizers.Adam(), loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "directory = './checkpoints-copy'\n",
    "# Name of the checkpoint files\n",
    "file_prefix = os.path.join(directory, \"ckpt_{epoch}\")\n",
    "\n",
    "callback=[tf.keras.callbacks.ModelCheckpoint(filepath=file_prefix, save_weights_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 6.2385\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.1467\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.0348\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.6879\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 14.8114\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.3257\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.4326\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.4660\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.4715\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.3514\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.2778\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.0558\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.7780\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.4221\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.1897\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.1974\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.1293\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.9174\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.0170\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.9479\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.9460\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.0113\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.9055\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.8516\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.7673\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.7067\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.6398\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.6888\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3470\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.4402\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.5343\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4948\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.3464\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.4167\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.1927\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.1535\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.2775\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.2231\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.1687\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.9772\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0643\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.8582\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.8050\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.8025\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.8667\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.7834\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.6451\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.7081\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.6089\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.5845\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4438\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.3684\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4260\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2379\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1574\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1071\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1995\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0593\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0928\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8550\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9905\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8621\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9142\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7591\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7779\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7538\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7270\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6850\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6281\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6415\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4952\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4870\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4992\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3909\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4095\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4287\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2652\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2890\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2974\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3293\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3138\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1073\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2397\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1544\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1299\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0577\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1523\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0898\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0948\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1070\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9867\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9505\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0055\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9838\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9682\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8766\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9306\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7926\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8836\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8571\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8076\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8076\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8509\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8381\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7774\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7745\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7602\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7522\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7354\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7473\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7338\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7164\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6088\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5789\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6444\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6490\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5165\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6072\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6225\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5374\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5074\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5692\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5346\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4711\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5623\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5075\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5164\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4583\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4835\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4762\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5018\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4281\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4229\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3892\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4356\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3402\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3564\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4044\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4231\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4441\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4079\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3896\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3762\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4002\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3352\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3098\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3648\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3734\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3373\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3258\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3408\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3509\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3061\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2856\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2561\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2960\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2663\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2896\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3099\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2453\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3078\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3049\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2849\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2829\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2406\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2814\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2689\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2579\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2357\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2587\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2588\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2571\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2120\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2340\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1705\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2340\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2173\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2044\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1794\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1886\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1974\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1966\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1827\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2068\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1758\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2052\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1974\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1898\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1974\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1951\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2006\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1781\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1843\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1676\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1638\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1638\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1537\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1756\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1347\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1592\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1614\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1593\n",
      "Epoch 204/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1550\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1627\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1407\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1468\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1498\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1132\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1397\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1454\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1359\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1372\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1311\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1288\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1303\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1214\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1208\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1236\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0966\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1180\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0909\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1234\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1080\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1199\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1129\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0997\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0974\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1137\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0920\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1039\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0941\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0894\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1039\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0896\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0896\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0853\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0945\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0949\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0850\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0876\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0748\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0830\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0836\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0933\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0760\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0804\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0667\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0867\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0897\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0846\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0803\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0826\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0776\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0724\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0713\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0801\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0753\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0680\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0692\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0687\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0781\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0699\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0647\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0595\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0595\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0623\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0614\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0699\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0643\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0614\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0537\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0708\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0556\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0567\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0554\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0534\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0582\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0549\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0531\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0563\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0501\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0516\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0506\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0495\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0585\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0512\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0514\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0448\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0514\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0517\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0494\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0470\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0454\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0490\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0415\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0396\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0471\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0486\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0413\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0451\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0498\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0445\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0457\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0479\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0431\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0384\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0377\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0410\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0443\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0402\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0396\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0425\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0391\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0472\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0462\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0369\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0376\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0392\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0412\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0412\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0384\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0413\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0364\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0370\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0369\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0373\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0332\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0365\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0360\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0399\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0348\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0363\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0326\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0343\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0359\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0370\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0327\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0320\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0364\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0554\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0398\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0461\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0342\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0486\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0359\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0468\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0386\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0372\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0385\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0429\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0370\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0337\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0376\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0382\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0358\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0364\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0348\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0345\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0305\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0299\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0341\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0313\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0313\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0322\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0308\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0312\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0267\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0320\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0257\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0283\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0295\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0317\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0280\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0244\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0243\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0300\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0247\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0270\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0244\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0245\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0273\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0244\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0244\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0256\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0273\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0240\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0230\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0220\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0230\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0230\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0243\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0245\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0198\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0213\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0230\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0193\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0235\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0255\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0201\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0217\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0217\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0213\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0212\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0182\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0207\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0189\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0203\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0207\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0224\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0197\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0198\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0201\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0204\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0181\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0207\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0194\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0214\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0208\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0190\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0207\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0175\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0192\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0173\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0199\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0214\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0192\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0193\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0166\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0203\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0178\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0212\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0188\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0154\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0180\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0204\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0205\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0172\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0199\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0178\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0191\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0174\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0170\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0186\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0168\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0180\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0182\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0180\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0178\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0174\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0147\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0175\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0168\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0180\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0147\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0195\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0141\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0170\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0141\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0148\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0172\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0154\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0152\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0148\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0140\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0167\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0150\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0167\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0145\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0148\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0146\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0147\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0162\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0165\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0149\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0169\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0140\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0160\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0146\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0158\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0136\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0160\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0163\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0144\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0141\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0158\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0141\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0164\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0153\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0145\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0145\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0153\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0128\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0142\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0157\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0123\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0160\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0149\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0146\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0141\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3072)\n",
      "(1024, 3072)\n",
      "(6144,)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (20, None, 512)           262144    \n",
      "_________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)       (20, None, 1024)          4724736   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (20, None, 512)           524800    \n",
      "=================================================================\n",
      "Total params: 5,511,680\n",
      "Trainable params: 5,511,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[1:2]:\n",
    "    weights = layer.get_weights() \n",
    "    for s in weights:\n",
    "        print(s.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints-copy/ckpt_500'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocabulary_size, embedding_dimension, recurrent_nn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(directory))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3072)\n",
      "(1024, 3072)\n",
      "(6144,)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (1, None, 512)            262144    \n",
      "_________________________________________________________________\n",
      "cu_dnngru_6 (CuDNNGRU)       (1, None, 1024)           4724736   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (1, None, 512)            524800    \n",
      "=================================================================\n",
      "Total params: 5,511,680\n",
      "Trainable params: 5,511,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[1:2]:\n",
    "    weights = layer.get_weights() \n",
    "    for s in weights:\n",
    "        print(s.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature, characters_to_generate):\n",
    "\n",
    "  # Vectorise  start string into numbers\n",
    "    input_string = [c2emb[code] for code in start_string]\n",
    "    input_string = tf.expand_dims(input_string, 0)\n",
    "\n",
    "  # Empty string to store  generated text\n",
    "    generated = start_string\n",
    "    \n",
    "  # (Batch size is 1)\n",
    "    model.reset_states()\n",
    "    for i in range(characters_to_generate):\n",
    "        predictions = model(input_string)\n",
    "        print(input_string.shape)\n",
    "      # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(logits=predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "        input_string = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        generated.append(emb2c[predicted_id])\n",
    "\n",
    "    return generated # generated is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-89c71f72c274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacters_to_generate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-7b9fdea77d17>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, start_string, temperature, characters_to_generate)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacters_to_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# remove the batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/layers/cudnn_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0;31m# Reverse time axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/keras/layers/cudnn_recurrent.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, inputs, initial_state)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         ],\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_SliceHelperVar\u001b[0;34m(var, slice_spec)\u001b[0m\n\u001b[1;32m   1291\u001b[0m   \"\"\"\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_slice_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1020\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1023\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1024\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zebra/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model=model, start_string=[text[np.random.randint(len(text))]], temperature=0.1, characters_to_generate = 12000)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"fish_murme2.npy\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
